<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Test Result</title>
  <link rel="stylesheet" href="styles.css">
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
  <header>
    <h1>Completed</h1>
    <div class="progress-bar">
      <div class="progress-3"></div>
    </div>
  </header>
  <img src="result-img.jpg" alt="Result Image" id="result-img">
  <div class="container">
    <h1>Survey Results</h1>
    <div id="resultPage1" class="result"></div>
    <div id="resultPage2" class="result"></div>
    <div id="predictionResult" class="result"></div>
  </div>
  <a href="index.html" class="start-button">Take the Test Again</a>

  <script>
    // Function to load the ONNX model
    async function loadModel() {
      try {
        const session = await ort.InferenceSession.create('./model.onnx'); // Adjust the path if necessary
        return session;
      } catch (error) {
        console.error("Error loading the model: ", error);
        document.getElementById('predictionResult').innerText = "Model loading failed.";
      }
    }

    // Function to retrieve URL parameters (scorePage1 and scorePage2)
    function getQueryParam(param) {
      let urlParams = new URLSearchParams(window.location.search);
      return urlParams.get(param);
    }

    // Function to make a prediction using the ONNX model
    async function makePrediction(session) {
      try {
        // Get scores from URL parameters
        let scorePage1 = parseFloat(getQueryParam('scorePage1'));
        let scorePage2 = parseFloat(getQueryParam('scorePage2'));

        // Prepare input tensor for ONNX model
        const inputTensor = new ort.Tensor('float32', [scorePage1, scorePage2], [1, 2]);

        // Run inference
        const feeds = { 'float_input': inputTensor }; // Ensure 'float_input' matches the actual input name
        const output = await session.run(feeds);

        // Extract outputs (Ensure 'output_label' and 'output_probability' match the actual output names)
        const labelTensor = output.get('output_label'); // Access by name (recommended)
        const probabilityTensor = output.get('output_probability'); // Access by name (recommended)

        // Extract data from tensors
        const label = labelTensor.data[0]; // For tensor with shape [0]
        const probability = probabilityTensor.data[0]; // For scalar value

        // Display prediction results
        document.getElementById('predictionResult').innerText = `Prediction: Label = ${label}, Probability = ${probability}`;
      } catch (error) {
        console.error("Error during prediction: ", error);
        document.getElementById('predictionResult').innerText = "Prediction failed.";
      }
    }

    // Main function execution
    (async function() {
      // Load the ONNX model
      let session = await loadModel();

      // Get and display the scores from URL parameters
      let scorePage1 = getQueryParam('scorePage1');
      let scorePage2 = getQueryParam('scorePage2');

      document.getElementById('resultPage1').innerText = `Page 1 Score: ${scorePage1}`;
      document.getElementById('resultPage2').innerText = `Page 2 Score: ${scorePage2}`;

      // Make a prediction using the loaded model
      if (session) {
        await makePrediction(session);
      }
    })();
  </script>
</body>
</html>